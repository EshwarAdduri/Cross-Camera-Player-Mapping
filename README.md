
# ğŸƒâ€â™‚ï¸ Player Re-Identification: Cross-Camera Player Mapping

## ğŸ“Œ Overview

This project implements a solution for **player re-identification across multiple camera views** in sports footage. Given two videos from different camera angles (`broadcast.mp4` and `tacticam.mp4`), the system ensures that each player retains a **consistent ID** across both views using computer vision techniques and deep learning.

---

## ğŸš€ Key Features

- ğŸ¯ **Fine-tuned YOLOv8** model for player/ball detection  
- ğŸ“¹ **ByteTrack** for robust player tracking across frames  
- ğŸ” **OSNet** for appearance-based feature extraction  
- â†”ï¸ **Cross-camera mapping** using cosine similarity + Hungarian algorithm  
- ğŸ“Š **Visualized results** with consistent player IDs  

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ videos/
â”‚   â”œâ”€â”€ broadcast.mp4
â”‚   â””â”€â”€ tacticam.mp4
â”œâ”€â”€ main.py
â”œâ”€â”€ player_mapping.json
â”œâ”€â”€ broadcast_result.mp4
â”œâ”€â”€ tacticam_result.mp4
â”œâ”€â”€ best.pt
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Download Model Weights

Place the YOLOv8 model file (`best.pt`) in the project root directory.

> ğŸ“¥ **Download Link:** [Download best.pt](https://drive.google.com/file/d/1-5fOSHOSB9UXyP_enOoZNAMScrePVcMD/view)

---

## ğŸ§  How to Run

Run the main pipeline with:

```use the notebook and run the cell
main.ipynb
```

### Output Files

- `player_mapping.json` â€“ Mapping between player IDs across cameras  
- `broadcast_result.mp4` â€“ Broadcast view with consistent player IDs  
- `tacticam_result.mp4` â€“ Tacticam view with consistent player IDs  

---

## ğŸ§ª Methodology

### ğŸ“· Player Detection & Tracking

- Model: YOLOv8 + ByteTrack  
- Confidence Threshold: `0.3` (to detect occluded players)  
- Tracks players persistently across frames  

### ğŸ§¬ Feature Extraction

- Network: OSNet (`osnet_x1_0`) from `torchreid`  
- Input: 128x256 RGB crops resized from bounding boxes  
- Output: Aggregated feature vector per track  

### ğŸ” Cross-Camera Matching

- Metric: Cosine similarity  
- Assignment: Hungarian algorithm  
- Threshold: Similarity > `0.5` for valid matches  

### ğŸ¨ Visualization

- âœ… Green box: Successfully mapped player  
- âŒ Red box: Unmapped player  
- ğŸ†” Displayed player ID on bounding box  

---

## ğŸ§© Challenges & Solutions

### Occlusion Handling

- Used ByteTrack for persistent ID tracking  
- Lowered detection threshold to detect partially visible players  

### Viewpoint Variation

- Aggregated features across time  
- Used viewpoint-invariant OSNet model  

### Lighting Differences

- Feature normalization before similarity comparison  
- Used cosine similarity instead of Euclidean distance  

### Performance Optimization

- Batched feature extraction  
- Frame skipping during visualization  

---
## Performance & Hardware Notes

- The entire pipeline took approximately **12 minutes** to run on a **CPU-only setup**.
- If executed with **GPU acceleration** (via CUDA, cuDNN, PyTorch, or TensorFlow), runtime can be significantly reduced, allowing near real-time inference and handling of longer videos more efficiently.
---

## ğŸ“¦ Dependencies

Tested with **Python 3.8+**

Install with:

```bash
pip install -r requirements.txt
```

---
